name: Update Trading Data Cache

on:
  schedule:
    # Run every hour at minute 0
    - cron: '0 * * * *'
  
  workflow_dispatch:
    # Allow manual triggering
    inputs:
      max_workers:
        description: 'Maximum number of concurrent workers'
        required: false
        default: '10'
        type: string

jobs:
  update-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        # Fetch full history to avoid issues with commits
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('trading_signal_app/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r trading_signal_app/requirements.txt
    
    - name: Create data cache directory
      run: |
        mkdir -p trading_signal_app/data_cache/{1h,4h,1d}
    
    # --- MODIFIED STEP ---
    # Now correctly reflects that it's using yfinance, not an external API
    - name: Run data pipeline with yfinance
      env:
        MAX_WORKERS: ${{ github.event.inputs.max_workers || '10' }}
      run: |
        echo "Starting data pipeline using yfinance..."
        python trading_signal_app/data_pipeline.py
    
    - name: Check pipeline results
      id: check_results
      run: |
        if [ -f "trading_signal_app/data_cache/pipeline_summary.txt" ]; then
          echo "Pipeline summary found"
          cat trading_signal_app/data_cache/pipeline_summary.txt
          
          if grep -q "Failed tasks: 0" trading_signal_app/data_cache/pipeline_summary.txt; then
            echo "pipeline_success=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Pipeline completed with no failures."
          elif grep -q "Successful tasks: 0" trading_signal_app/data_cache/pipeline_summary.txt; then
            echo "pipeline_success=false" >> $GITHUB_OUTPUT
            echo "‚ùå Pipeline completed but NO data was successfully processed."
          else
            echo "pipeline_success=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Pipeline completed with some successful data processing."
          fi
        else
          echo "pipeline_success=false" >> $GITHUB_OUTPUT
          echo "‚ùå No pipeline summary found."
        fi

    - name: Check if data was updated
      id: check_changes
      run: |
        if [ -n "$(git status --porcelain trading_signal_app/data_cache/)" ]; then
          echo "changes=true" >> $GITHUB_OUTPUT
          echo "Data cache has been updated."
        else
          echo "changes=false" >> $GITHUB_OUTPUT
          echo "No changes to data cache."
        fi
    
    # --- MODIFIED STEP ---
    # Added 'git pull --rebase' to prevent "non-fast-forward" errors.
    - name: Commit and push changes
      if: steps.check_changes.outputs.changes == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add the updated cache and log files
        git add trading_signal_app/data_cache/
        git add trading_signal_app/data_pipeline.log
        
        # Commit the changes
        git commit -m "ü§ñ Auto-update trading data cache - $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        
        # *** KEY CHANGE HERE ***
        # Pull latest changes from the remote branch and rebase our commit on top of them
        git pull --rebase
        
        # Push the changes
        git push
    
    - name: Upload pipeline logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-logs-${{ github.run_number }}
        path: |
          trading_signal_app/data_pipeline.log
          trading_signal_app/data_cache/pipeline_summary.txt
        retention-days: 7
    
    - name: Create summary comment
      if: always()
      run: |
        echo "## üìä Data Pipeline Summary" >> $GITHUB_STEP_SUMMARY
        echo "**Trigger:** ${{ github.event_name == 'workflow_dispatch' && 'Manual' || 'Scheduled' }}" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "trading_signal_app/data_cache/pipeline_summary.txt" ]; then
          echo "### Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat trading_signal_app/data_cache/pipeline_summary.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "### Changes Made" >> $GITHUB_STEP_SUMMARY
        if [ "${{ steps.check_changes.outputs.changes }}" = "true" ]; then
          echo "‚úÖ Data cache updated and committed to the repository." >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ÑπÔ∏è No changes were detected in the data cache." >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Notify on complete failure
      if: steps.check_results.outputs.pipeline_success == 'false'
      run: |
        echo "‚ùå Pipeline failed to process any data successfully. Check logs for details."
        exit 1
