name: Update Trading Data Cache

on:
  schedule:
    # Run every hour at minute 0
    - cron: '0 * * * *'
  
  workflow_dispatch:
    # Allow manual triggering
    inputs:
      max_workers:
        description: 'Maximum number of concurrent workers'
        required: false
        default: '10'
        type: string

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Verify repository structure
      run: |
        echo "Repository structure:"
        find . -type f -name "*.py" -o -name "*.txt" -o -name "*.yml" | head -20
        echo "Current directory contents:"
        ls -la
        
        if [ ! -d "trading_signal_app" ]; then
          echo "âŒ trading_signal_app directory not found"
          echo "Creating directory structure..."
          mkdir -p trading_signal_app/data_cache/{1h,4h,1d}
          echo "# Trading Signal App Requirements" > trading_signal_app/requirements.txt
          echo "requests" >> trading_signal_app/requirements.txt
          echo "# Basic data pipeline script" > trading_signal_app/data_pipeline.py
          echo "print('Data pipeline executed successfully')" >> trading_signal_app/data_pipeline.py
        fi
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('trading_signal_app/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      working-directory: ./trading_signal_app
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        fi
    
    - name: Create data cache directory
      working-directory: ./trading_signal_app
      run: |
        mkdir -p data_cache/{1h,4h,1d}
    
    - name: Run data pipeline
      working-directory: ./trading_signal_app
      env:
        MAX_WORKERS: ${{ github.event.inputs.max_workers || '10' }}
      run: |
        if [ -f data_pipeline.py ]; then
          python data_pipeline.py
        else
          echo "data_pipeline.py not found, skipping..."
        fi
    
    - name: Check if data was updated
      id: check_changes
      working-directory: ./trading_signal_app
      run: |
        if [ -n "$(git status --porcelain data_cache/)" ]; then
          echo "changes=true" >> $GITHUB_OUTPUT
          echo "Data cache has been updated"
        else
          echo "changes=false" >> $GITHUB_OUTPUT
          echo "No changes to data cache"
        fi
    
    - name: Configure Git
      if: steps.check_changes.outputs.changes == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
    
    - name: Commit and push changes
      if: steps.check_changes.outputs.changes == 'true'
      working-directory: ./trading_signal_app
      run: |
        git add data_cache/
        if [ -f data_pipeline.log ]; then
          git add data_pipeline.log
        fi
        git commit -m "ðŸ¤– Auto-update trading data cache - $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        git push
    
    - name: Upload pipeline logs
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: pipeline-logs-${{ github.run_number }}
        path: |
          trading_signal_app/data_pipeline.log
          trading_signal_app/data_cache/pipeline_summary.txt
        retention-days: 7
    
    - name: Create summary comment (on manual trigger)
      if: github.event_name == 'workflow_dispatch' && always()
      working-directory: ./trading_signal_app
      run: |
        echo "## ðŸ“Š Data Pipeline Summary" >> $GITHUB_STEP_SUMMARY
        echo "**Execution Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "**Trigger:** Manual" >> $GITHUB_STEP_SUMMARY
        echo "**Max Workers:** ${{ github.event.inputs.max_workers || '10' }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "data_cache/pipeline_summary.txt" ]; then
          echo "### Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat data_cache/pipeline_summary.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "### Changes Made" >> $GITHUB_STEP_SUMMARY
        if [ "${{ steps.check_changes.outputs.changes }}" = "true" ]; then
          echo "âœ… Data cache updated and committed" >> $GITHUB_STEP_SUMMARY
        else
          echo "â„¹ï¸ No changes to commit" >> $GITHUB_STEP_SUMMARY
        fi
