name: Update Trading Data Cache

on:
  schedule:
    # Run every hour at minute 0
    - cron: '0 * * * *'
  
  workflow_dispatch:
    # Allow manual triggering
    inputs:
      max_workers:
        description: 'Maximum number of concurrent workers'
        required: false
        default: '10'
        type: string
      continue_on_failure:
        description: 'Continue workflow even if some data fetching fails'
        required: false
        default: 'true'
        type: boolean

jobs:
  update-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        # Fetch full history to avoid issues with commits
        fetch-depth: 0
        # Use the GITHUB_TOKEN for authentication
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('trading_signal_app/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      working-directory: ./trading_signal_app
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data cache directory
      working-directory: ./trading_signal_app
      run: |
        mkdir -p data_cache/{1h,4h,1d}
    
    - name: Run data pipeline
      working-directory: ./trading_signal_app
      env:
        MAX_WORKERS: ${{ github.event.inputs.max_workers || '10' }}
        CONTINUE_ON_FAILURE: ${{ github.event.inputs.continue_on_failure || 'true' }}
      run: |
        echo "Starting forex data pipeline with API endpoint..."
        python data_pipeline.py
    
    - name: Check pipeline results
      id: check_results
      working-directory: ./trading_signal_app
      run: |
        if [ -f "data_cache/pipeline_summary.txt" ]; then
          echo "Pipeline summary found"
          cat data_cache/pipeline_summary.txt
          
          # Check if any data was successfully processed
          if grep -q "Success rate: 0.0%" data_cache/pipeline_summary.txt; then
            echo "pipeline_success=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è Pipeline completed but no data was successfully processed"
          else
            echo "pipeline_success=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Pipeline completed with some successful data processing"
          fi
        else
          echo "pipeline_success=false" >> $GITHUB_OUTPUT
          echo "‚ùå No pipeline summary found"
        fi
    
    - name: Check if data was updated
      id: check_changes
      working-directory: ./trading_signal_app
      run: |
        if [ -n "$(git status --porcelain data_cache/)" ]; then
          echo "changes=true" >> $GITHUB_OUTPUT
          echo "Data cache has been updated"
        else
          echo "changes=false" >> $GITHUB_OUTPUT
          echo "No changes to data cache"
        fi
    
    - name: Configure Git
      if: steps.check_changes.outputs.changes == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
    
    - name: Commit and push changes
      if: steps.check_changes.outputs.changes == 'true'
      working-directory: ./trading_signal_app
      run: |
        # Configure git to ignore warnings about ignored files
        git config advice.addIgnoredFile false
        
        # Add only the data_cache directory (skip log files that might be ignored)
        git add data_cache/
        
        # Try to add log file, but don't fail if it's ignored
        git add data_pipeline.log 2>/dev/null || echo "Log file ignored by .gitignore, skipping"
        
        # Check if there are actually changes to commit
        if git diff --staged --quiet; then
          echo "No staged changes to commit"
          exit 0
        fi
        
        git commit -m "ü§ñ Auto-update trading data cache - $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        git push
    
    - name: Upload pipeline logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-logs-${{ github.run_number }}
        path: |
          trading_signal_app/data_pipeline.log
          trading_signal_app/data_cache/pipeline_summary.txt
        retention-days: 7
    
    - name: Create summary comment
      if: always()
      working-directory: ./trading_signal_app
      run: |
        echo "## üìä Data Pipeline Summary" >> $GITHUB_STEP_SUMMARY
        echo "**Execution Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "**Trigger:** ${{ github.event_name == 'workflow_dispatch' && 'Manual' || 'Scheduled' }}" >> $GITHUB_STEP_SUMMARY
        echo "**Max Workers:** ${{ github.event.inputs.max_workers || '10' }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "data_cache/pipeline_summary.txt" ]; then
          echo "### Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat data_cache/pipeline_summary.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "### Changes Made" >> $GITHUB_STEP_SUMMARY
        if [ "${{ steps.check_changes.outputs.changes }}" = "true" ]; then
          echo "‚úÖ Data cache updated and committed" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ÑπÔ∏è No changes to commit" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "### Pipeline Status" >> $GITHUB_STEP_SUMMARY
        if [ "${{ steps.check_results.outputs.pipeline_success }}" = "true" ]; then
          echo "‚úÖ Pipeline completed successfully" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚ö†Ô∏è Pipeline encountered issues - check logs for details" >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Notify on complete failure
      if: steps.check_results.outputs.pipeline_success == 'false' && github.event.inputs.continue_on_failure != 'true'
      run: |
        echo "‚ùå Pipeline failed completely with no successful data processing"
        echo "Consider checking:"
        echo "1. API credentials and rate limits"
        echo "2. Network connectivity"
        echo "3. Symbol validity and data source availability"
        echo "4. Data pipeline configuration"
        exit 1
